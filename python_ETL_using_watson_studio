#Watson Studio own exercise full ETL practice

#Skills network lab is a learning environment; in the next section, you will use Watson Studio, a production environment that will allow you to share your lab for marking. Watson Studio provides a suite of tools and a collaborative environment for data scientists, developers and domain experts.

#Put my code into Watson which is a cloud based environment supported by IBM which includes Python Notebook. I can run all my python code there.

#Peer Review Assignment - Data Engineer - ETL
#Estimated time needed: 20 minutes
# Objectives
# In this final part you will:
# Run the ETL process
# Extract bank and market cap data from the JSON file bank_market_cap.json
# Transform the market cap currency using the exchange rate data
# Load the transformed data into a seperate CSV
# For this lab, we are going to be using Python and several Python libraries. Some of these libraries might be installed in your lab environment or in SN Labs. Others may need to be installed by you. The cells below will install these libraries when executed.

#!mamba install pandas==1.3.3 -y
#!mamba install requests==2.26.0 -y
#Imports
#Import any additional libraries you may need here.

import glob
import pandas as pd
from datetime import datetime
from pandas.io.json import json_normalize


# As the exchange rate fluctuates, we will download the same dataset to make marking simpler. This will be in the same format as the dataset you used in the last section

# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/bank_market_cap_1.json
# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/bank_market_cap_2.json
# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Final%20Assignment/exchange_rates.csv

# logfile_name
logfile    = "bank_market_rates_logfile.txt"            # all event logs will be stored in this file

# Extract
# JSON Extract Function
# This function will extract JSON files.

#url = "https://api.apilayer.com/exchangerates_data/latest?base=EUR&apikey=*****Your API Key*****" #Make sure to change ******* to your API key.
url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/bank_market_cap_1.json"
url2 = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/bank_market_cap_2.json"
url3 = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Final%20Assignment/exchange_rates.csv"

# Extract Function
def extract(url,url2,url3):
    # Define the extract function that finds JSON file bank_market_cap_1.json and calls the function created above to extract data from them. Store the data in a pandas dataframe. Use the following list for the columns.
    #url1
    response = requests.get(url)
    data=response.json()
    data_keys=list(data.keys())# 2 1st keys
    df2=pd.DataFrame()
    for count,value in enumerate(data_keys):
        nested_dict=list(data[data_keys[count]].keys())
        df=pd.DataFrame(columns=['1'])
        for count2,value2 in enumerate(nested_dict):
            nested_dict_value=data[data_keys[count]][nested_dict[count2]]
            df.loc[count2,'1']=nested_dict_value
        df2 = pd.concat([df2, df], axis=1)
    df2.columns  = ['Name','Market Cap (US$ Billion)']

    #url2
    data=[]
    response = requests.get(url2)
    data=response.json()
    data_keys=list(data.keys())# 2 1st keys
    df3=pd.DataFrame()
    for count,value in enumerate(data_keys):
        nested_dict=list(data[data_keys[count]].keys())
        df=pd.DataFrame(columns=['1'])
        for count2,value2 in enumerate(nested_dict):
            nested_dict_value=data[data_keys[count]][nested_dict[count2]]
            df.loc[count2,'1']=nested_dict_value
        df3 = pd.concat([df3, df], axis=1)
    df3.columns  = ['Name','Market Cap (US$ Billion)']
    # append 2 dataframes
    dataframe4=pd.DataFrame()
    dataframe4=dataframe4.append(df2,ignore_index = True)
    dataframe4=dataframe4.append(df3,ignore_index = True)
#     print('json')
#     print(dataframe4)
    
    # # if files are saved on local computer,I should be able to do that.
    # def extract_from_json(file_to_process):
    #     dataframe = pd.read_json(file_to_process)
    #     return dataframe
    # #Extract Function
    # #Define the extract function that finds JSON file bank_market_cap_1.json and calls the function created above to extract data from them. Store the data in a pandas dataframe. Use the following list for the columns.
    # columns=['Name','Market Cap (US$ Billion)']
    # def extract():
    #     extracted_data = pd.DataFrame(columns=columns)
    #     for jsonfile in glob.glob("*.json"):
    #         extracted_data = extracted_data.append(extract_from_json(jsonfile),ignore_index=True)
    #         extracted_data.replace("\n","",inplace=True, regex=True)
    #     return extracted_data
        
    # Question 1 Load the file exchange_rates.csv as a dataframe and find the exchange rate for British pounds with the symbol GBP, store it in the variable exchange_rate, you will be asked for the number. Hint: set the parameter index_col to 0.
    dataframe5=pd.DataFrame()
    dataframe5=pd.read_csv(url3)
    dataframe5.columns  = ['Name','Rates']
#     print('csv')
#     print(dataframe5)
    return dataframe4,dataframe5

# Transform
# Using exchange_rate and the exchange_rates.csv file find the exchange rate of USD to GBP. Write a transform function that
# Changes the Market Cap (US$ Billion) column from USD to GBP
# Rounds the Market Cap (US$ Billion)` column to 3 decimal places
# Rename Market Cap (US$ Billion) to Market Cap (GBP$ Billion)
def transform(dataframe1,dataframe2):
    exchange_rate_gbp=dataframe2.loc[dataframe2['Name']=='GBP'] # or exchange_rate_gbp=rates.at['GBP','Rates']
    exchange_rate_gbp=exchange_rate_gbp.iloc[0,1]
    print(exchange_rate_gbp)
    dataframe1['Market Cap (US$ Billion)'] = dataframe1['Market Cap (US$ Billion)'].astype(float)
    dataframe1['Market Cap (US$ Billion)'] = round(dataframe1['Market Cap (US$ Billion)']*exchange_rate_gbp,3)# can add any math operation in here. *= stands for it will apply math operation to all elements in the dataframe
    dataframe1.columns  = ['Name','Market Cap (GBP$ Billion)']
    return dataframe1

# Load
# Create a function that takes a dataframe and load it to a csv named bank_market_cap_gbp.csv. Make sure to set index to False.
def load(dataframe):
    filepath='bank_market_cap_gbp.csv'
    dataframe.to_csv(filepath,index=False)     
    


# Logging Function
# Write the logging function log to log your data:
def log(message,logfile):
    current_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with open(logfile, 'a') as f:
        data = f.write('current time: {}--- message: {}  \n'.format(current_time,message))



# Running the ETL Process
# Log the process accordingly using the following "ETL Job Started" and "Extract phase Started"
message=('ETL Job Started')
log(message,logfile)
# Extract
# Question 2 Use the function extract, and print the first 5 rows, take a screen shot:
message=('Extract Phase Started')
log(message,logfile)
# Call the function here
dataframe1,dataframe2=extract(url,url2,url3)
print('json data name and bank rates--> {}'.format(dataframe1.iloc[0:5]))
print('csv file of currency rates--> {}'.format(dataframe2.iloc[0:5]))
# Print the rows here
message=('Extract phase Ended')
log(message,logfile)
# Transform
# Log the following "Transform phase Started"
message=('Transform Phase Started')
log(message,logfile)
# Question 3 Use the function transform and print the first 5 rows of the output, take a screen shot:
dataframe=transform(dataframe1,dataframe2)
print('transformed dataframe--> {}'.format(dataframe.iloc[0:5]))# Print the first 5 rows here
# Log your data "Transform phase Ended"
message=('Transform phase Ended')
log(message,logfile)
# Load
# Log the following "Load phase Started".
message=('Load Phase Started')
log(message,logfile)
# Write your code here
load(dataframe)
# Log the following "Load phase Ended".
message=('Load phase Ended')
log(message,logfile)
# Log the process accordingly using the following "ETL Job Ended"
message=('ETL Job Ended')
log(message,logfile)
